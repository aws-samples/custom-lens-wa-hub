{
    "schemaVersion": "2021-11-01",
    "name": "AWS Well-Architected ElastiCache Custom Lens",
    "description": "The ElastiCache Lens contains insights that AWS has gathered from real-world case studies, and helps you learn the key design elements of well-architected ElastiCache workloads along with recommendations for improvement. The document is intended for IT architects, developers, and team members who build and operate ElastiCache systems.",
    "_version":"1.0",
    "_release_date":"2023-05-23",
    "_release_note":"for public preview",
    "_teams":{
        "_authors":[
            {
                "name":"Lakshmi Peri, Sr. In-Memory DB SA, WWSO Database, AWS",
                "email":"lvperi@amazon.com"
            },
            {
              "name":"Ravi Thakur, Sr Solutions Architect, AWS BDSI SACS Architects",
              "email":"rrrthakur@amazon.com"
            },
            {
              "name":"Steven Hancz Sr. In-Memory DB SA, WWSO Database, AWS",
              "email":"shancz@amazon.com"
            }           
        ],
        "_tech_reviewers":[
            {
                "name":"Damon LaCaille Sr. In-Memory DB SA, WWSO Database, AWS",
                "note":"lacdamon@amazon.com"
            },
                {
                "name":"Roberto Luna Rojas Sr. In-Memory DB SA, WWSO Database, AWS",
                "note":"rberoj@amazon.com"
            }
      ]
    },
    "pillars": [
      {
        "id": "waf_ec_1_ops",
        "name": "Operational excellence",
        "questions": [
          {
            "id": "waf_ec_ops_dp1",
            "title": "How do you understand and respond to alerts and events triggered by your ElastiCache cluster?",
            "description": "When you operate ElastiCache clusters you can optionally receive notifications and alerts when specific events occur. ElastiCache, by default, logs events that relate to your resources, such as a failover, node replacement, scaling operation, scheduled maintenance, and more. Each event includes the date and time, the source name and source type, and a description",
            "choices": [
              {
                "id": "waf_ec_ops_dp1_bp1",
                "title": "Configure ElastiCache to send notifications for important cluster events",
                "improvementPlan": {
                  "displayText": "Consult, on a daily basis, the events generated by ElastiCache on the ElastiCache console (after selecting your region) or using the Amazon Command Line Interface (AWS CLI) describe-events command and the ElastiCache API. Configure ElastiCache to send notifications for important cluster events using Amazon Simple Notification Service (Amazon SNS). Using Amazon SNS with your clusters allows you to programmatically take actions upon ElastiCache events. - There are 2 large categories of events: current and scheduled events. The list of current events includes: resource creation and deletion, scaling operations, failover, node reboot, snapshot created, cluster’s parameter modification, CA certificate renewal, failure events (cluster provisioning failure - VPC or ENI-, scaling failures - ENI-, and snapshot failures). The list of scheduled events includes: node scheduled for replacement during the maintenance window and node replacement rescheduled.  - Although you may not need to react immediately to some of these events, it is critical to first look at all failure events: ElastiCache:AddCacheNodeFailed, ElastiCache:CacheClusterProvisioningFailed, ElastiCache:CacheClusterScalingFailed, ElastiCache:CacheNodesRebooted, ElastiCache:SnapshotFailed (Redis only);", 
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ECEvents.SNS.html"
                },
                "helpfulResource":
                    {
                      "displayText": "Being able to understand and manage the underlying reasons behind the events that trigger alerts generated by your cluster enables you to operate more effectively and respond to events appropriately.",
                      "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ElastiCacheSNS.html"
                    }
              },
              {
                "id": "waf_ec_ops_dp1_bp2",
                "title": "Automate responses to events, use SNS to send emails to ElastiCache administrators",
                "improvementPlan": {
                  "displayText": "To automate responses to events, use SNS to send emails to ElastiCache administrators. You should use Amazon CloudWatch metrics to monitor your clusters.",
                  "url": "https://aws.amazon.com/blogs/database/monitor-amazon-elasticache-for-redis-cluster-mode-disabled-read-replica-endpoints-using-aws-lambda-amazon-route-53-and-amazon-sns/"
  
                },
                "helpfulResource": {
                  "displayText": "As a best practice and for workload balancing, you should direct read requests to read replicas. However, if a failover occurs, a previously used read replica could be promoted to the primary role. Continuing to direct read requests to the same endpoint can increase the load on the new primary (the old read replica). In such cases, with cluster-mode-disabled clusters, it is useful to have a read replica endpoint that always points to a replica, even after a failover.",
                  "url": "https://aws.amazon.com/blogs/database/monitor-amazon-elasticache-for-redis-cluster-mode-disabled-read-replica-endpoints-using-aws-lambda-amazon-route-53-and-amazon-sns/"
                }
              },
              {
                "id": "waf_ec_ops_dp1_bp3",
                "title": "None of these",
                "improvementPlan": {
                  "displayText": "Apply the recommended best practices"
                },
                "helpfulResource": {
                  "displayText": "Choose this if your workload does not follow these best practices."
                }
              }
            ],
            "riskRules": [
              {
                "condition": "waf_ec_ops_dp1_bp3 || !waf_ec_ops_dp1_bp1",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_ops_dp1_bp2",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_ops_dp1_bp1 && waf_ec_ops_dp1_bp2",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_ops_dp2",
            "title": "When and how do you scale your existing ElastiCache clusters?",
            "description": "Right-sizing your ElastiCache cluster is a balancing act that needs to be evaluated every time there are changes to the underlying workload types. Your objective is to operate with the right sized environment for your workload so as not to overprovision or underprovision.",
            "choices": [
              {
                "id": "waf_ec_ops_dp2_bp1",
                "title": "CPU and network over utilization on primary nodes ",
                "improvementPlan": {
                  "displayText": "CPU and network over-utilization on primary nodes should be addressed by offloading and redirecting the read operations to replica nodes. Use replica nodes for read operations to reduce primary node utilization. This can be configured in your Redis client library by connecting to the ElastiCache reader endpoint for cluster mode disabled, or by using the Redis READONLY command for cluster mode enabled",
                  "url": "https://aws.amazon.com/blogs/database/five-workload-characteristics-to-consider-when-right-sizing-amazon-elasticache-redis-clusters/"
                },
                "helpfulResource": {
                  "displayText": "Over-utilization of your resources may result in elevated latency and overall decreased performance. Under-utilization, on the other hand, may result in over-provisioned resources. To remediate over or under utilization of your resources, ElastiCache can scale in two dimensions. You can scale vertically by increasing or decreasing node capacity. You can also scale horizontally by adding and removing shards.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html"
                }
              },
              {
                "id": "waf_ec_ops_dp2_bp2",
                "title": "Monitor the utilization of critical cluster resources such as CPU, memory, and network.",
                "improvementPlan": {
                  "displayText": "Monitor the utilization of critical cluster resources such as CPU, memory, and network. The utilization of these specific cluster resources needs to be tracked to inform your decision to scale, and the type of scaling operation. For ElastiCache for Redis cluster mode disabled, primary and replica nodes can scale vertically. Replica nodes can also scale horizontally from 0 to 5 nodes. For cluster mode enabled, the same applies within each shard of your cluster. In addition, you can increase or reduce the number of shards. For Memcached, scaling horizontally is the best practice for most use cases since scaling vertically requires the creation of a new cluster.",
                  "url": "https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/"
                },
                "helpfulResource": {
                  "displayText": "Over-utilization of your resources may result in elevated latency and overall decreased performance. Under-utilization, on the other hand, may result in over-provisioned resources. To remediate over or under utilization of your resources, ElastiCache can scale in two dimensions. You can scale vertically by increasing or decreasing node capacity. You can also scale horizontally by adding and removing shards.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Scaling.html"
                }
              },
              {
                  "id": "waf_ec_ops_dp2_bp3",
                  "title": "Do you monitor trends over time to detect workload changes",
                  "improvementPlan": {
                    "displayText": "Monitoring trends over time can help you detect workload changes that would remain unnoticed if monitored at a particular point in time. To detect longer term trends, use CloudWatch metrics to scan for longer time ranges. The learnings from observing extended periods of CloudWatch metrics should inform your forecast around cluster resources utilization. CloudWatch data points and metrics are available for up to 455 days",
                    "url": "https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/"
                  },
                  "helpfulResource": {
                    "displayText": "Over-utilization of your resources may result in elevated latency and overall decreased performance. Under-utilization, on the other hand, may result in over-provisioned resources. To remediate over or under utilization of your resources, ElastiCache can scale in two dimensions. You can scale vertically by increasing or decreasing node capacity. You can also scale horizontally by adding and removing shards.",
                    "url": "https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/"
                  }
              },
              {
                  "id": "waf_ec_ops_dp2_bp4",
                  "title": "Do you preserve operational consistency and avoid unmanaged configuration changes and stack drifts",
                  "improvementPlan": {
                    "displayText": "If your ElastiCache resources are created as Infrastructure as Code (IaC) it is best practice to perform changes using IaC templates to preserve operational consistency and avoid unmanaged configuration changes and stack drifts.",
                    "url": "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_ElastiCache.html"
                  },
                  "helpfulResource": {
                    "displayText": "If your ElastiCache resources are created with IaC it is best practice to perform changes using IaC templates to preserve operational consistency and avoid unmanaged configuration changes and stack drifts.",
                    "url": "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_ElastiCache.html"
                  }
              }, 
              {
                  "id": "waf_ec_ops_dp2_bp5",
                  "title": "Do you have autoscaling in place for variable workloads using Redis compatible compute engine",
                  "improvementPlan": {
                    "displayText": "Enable auto scaling for Redis Compatible Cluster mode Enabled cluster to scale resources for variable workloads. Auto scaling can add shards or read replicas to an existing cluster depending on CPU and Memory utilization.",
                    "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoScaling.html"
                  },
                  "helpfulResource": {
                    "displayText": "Use AWS CloudWatch to monitor your cluster and gather hitorical resource utilization data (for CPU and Memory utilization). Use the gathered dat to set auto scaling threshols that are appropriate for your workloads. Periodically re-visit this settins so that your scaling is addjusted for changes in worload.",
                    "url": "https://aws.amazon.com/blogs/database/scale-your-amazon-elasticache-for-redis-clusters-with-auto-scaling"
                  }
              }, 
              {
                "id": "waf_ec_ops_dp2_bp6",
                "title": "Do you use custom metrics (other then CPU and Memory) to scale a Redis compatible cluster",
                "improvementPlan": {
                  "displayText": "Automate your scaling operations using cluster operational data and define threshold(s) in CloudWatch to setup alarms. Use CloudWatch Events and Simple Notification Service (SNS) to trigger Lambda functions and execute an ElastiCache API to scale your clusters automatically. An example would be to add a shard to your cluster when the network bandwith alowed is exeded X times in Y period of time.",
                  "url": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html/"
                },
                "helpfulResource": {
                  "displayText": "Use AWS CloudWatch to gather historical resource utilization data on the resource that are important for your workload (other than CPU and Memory those are already automated). Do not create multiple auto scaling jobs that will adjust the same cluster.",
                  "url": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html"
                }
            },                                     
              {
                "id": "waf_ec_ops_dp2_bp7",
                "title": "None of these",
                "improvementPlan": {
                  "displayText": "Apply the recommended best practices"
                },
                "helpfulResource": {
                  "displayText": "Choose this if your workload does not follow these best practices."
                }
              }
            ],
            "riskRules": [
              {
                "condition": "waf_ec_ops_dp2_bp7 || !waf_ec_ops_dp2_bp1 || !waf_ec_ops_dp2_bp2 || !waf_ec_ops_dp2_bp5",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_ops_dp2_bp3 || !waf_ec_ops_dp2_bp4 || !waf_ec_ops_dp2_bp6 || !waf_ec_ops_dp2_bp7",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_ops_dp2_bp1 && waf_ec_ops_dp2_bp2 && waf_ec_ops_dp2_bp3 && waf_ec_ops_dp2_bp4 && waf_ec_ops_dp2_bp5 && waf_ec_ops_dp2_bp6 && waf_ec_ops_dp2_bp7",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_ops_dp3",
            "title": "How do you manage your ElastiCache cluster resources and maintain your cluster up-to-date?",
            "description": "When operating at scale, it is essential that you are able to pinpoint and identify all your ElastiCache resources. When rolling out new application features you need to create cluster version symmetry across all your ElastiCache environment types: dev, testing, and production. Resource attributes allow you to separate environments for different operational objectives, such as when rolling out new features and enabling new security mechanisms.",
            "choices": [
              {
                "id": "waf_ec_ops_dp3_bp1",
                "title": "Run on the latest engine version available and apply the Self-Service Updates as quickly as they become available.",
                "improvementPlan": {
                  "displayText": "Run on the latest engine version available and apply the Self-Service Updates as quickly as they become available. ElastiCache automatically updates its underlying infrastructure during your specified maintenance window of the cluster. However, the nodes running in your clusters are updated via Self-Service Updates. These updates can be of two types: security patches or minor software updates. Ensure you understand the difference between types of patches and when they are applied",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Self-Service-Updates.html"
                },
                "helpfulResource": {
                  "displayText": "Separating your development, testing, and production environments is best operational practice. It is also best practice that your clusters and nodes across environments have the latest software patches applied using well understood and documented processes. Taking advantage of native ElastiCache features enables your engineering team to focus on meeting business objectives and not on ElastiCache maintenance.",
                  "url": "https://aws.amazon.com/elasticache/elasticache-maintenance/"
                }
              },
              {
                "id": "waf_ec_ops_dp3_bp2",
                "title": "Organize your ElastiCache resources using tags",
                "improvementPlan": {
                  "displayText": "Organize your ElastiCache resources using tags. Use tags on replication groups and not on individual nodes. You can configure tags to be displayed when you query resources and you can use tags to perform searches and apply filters. You should use Resource Groups to easily create and maintain collections of resources that share common sets of tags.",
                  "url": "https://docs.aws.amazon.com/whitepapers/latest/tagging-best-practices/tagging-best-practices.html"
                },
                "helpfulResource": {
                  "displayText": "Separating your development, testing, and production environments is best operational practice. It is also best practice that your clusters and nodes across environments have the latest software patches applied using well understood and documented processes. Taking advantage of native ElastiCache features enables your engineering team to focus on meeting business objectives and not on ElastiCache maintenance.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Tagging-Resources.html"
                }
              },
              {
                "id": "waf_ec_ops_dp3_bp3",
                "title": "None of these",
                "improvementPlan": {
                  "displayText": "Apply the recommended best practices"
  
                },
                "helpfulResource": {
                  "displayText": "Choose this if your workload does not follow these best practices."
                }
              }
  
            ],
            "riskRules": [
              {
                "condition": "waf_ec_ops_dp3_bp1 && waf_ec_ops_dp3_bp2",
                "risk": "NO_RISK"
              },
              {
                "condition": "!waf_ec_ops_dp3_bp1 || !waf_ec_ops_dp3_bp2 || waf_ec_ops_dp3_bp3",
                "risk": "MEDIUM_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_ops_dp4",
            "title": "How do you model and interact with data in ElastiCache? ",
            "description": "ElastiCache is heavily application dependent on the data structures and the data model used. Understand the ElastiCache for Redis data structures available and ensure you are using the most appropriate data structures for your needs.",
            "choices": [
              {
                "id": "waf_ec_ops_dp4_bp1",
                "title": "Reduce unintentional overwriting of data",
                "improvementPlan": {
                  "displayText": "A best practice is to reduce unintentional overwriting of data. Use a naming convention that minimizes overlapping key names. Conventional naming of your data structures uses a hierarchical method such as: APPNAME:CONTEXT:ID, such as ORDER-APP:CUSTOMER:123",
                  "url": "https://docs.gitlab.com/ee/development/redis.html#key-naming"
                },
                "helpfulResource": {
                  "displayText": "Data modeling in ElastiCache has several layers, including application use case, data types, and relationships between data elements. Additionally, each ElastiCache for Redis data type and command have their own well-documented performance signatures.",
                  "url": "https://docs.gitlab.com/ee/development/redis.html#key-naming"
                }
              },
              {
                "id": "waf_ec_ops_dp4_bp2",
                "title": "Manage operations complexity with lower performance and potential operation timeouts",
                "improvementPlan": {
                  "displayText": "ElastiCache for Redis commands have a time complexity defined by the Big O notation. This time complexity of a command is an algorithmic/mathematical representation of its impact. When introducing a new data type in your application you need to carefully review the time complexity of the related commands. Commands with a time complexity of O(1) are constant in time and do not depend on the size of the input; however, commands with a time complexity of O(N) are linear in time and are subject to the size of the input. Due to the single threaded design of Redis, a large volume of high time complexity operations will result in lower performance and potential operation timeouts.",
                  "url": "https://redis.io/commands/"
                },
                "helpfulResource": {
                  "displayText": "Data modeling in ElastiCache has several layers, including application use case, data types, and relationships between data elements. Additionally, each ElastiCache for Redis data type and command have their own well documented performance signatures.",
                  "url": "https://redis.io/commands/"
                }
              },
              {
                  "id": "waf_ec_ops_dp4_bp3",
                  "title": "Visibility into the data model in your cluster",
                  "improvementPlan": {
                    "displayText": "Use APIs to gain GUI visibility into the data model in your cluster.",
                    "url": "https://github.com/humante/redis-browser"
                  },
                  "helpfulResource": {
                      "displayText": "Data modeling in ElastiCache has several layers, including application use case, data types, and relationships between data elements. Additionally, each ElastiCache for Redis data type and command have their own well documented performance signatures.",
                      "url": "https://github.com/humante/redis-browser"
                  }
                },
              {
                "id": "waf_ec_ops_dp4_bp4",
                "title": "None of these",
                "improvementPlan": {
                  "displayText": "Apply the recommended best practices"
  
                },
                "helpfulResource": {
                  "displayText": "Choose this if your workload does not follow these best practices."
                }
              }
  
            ],
            "riskRules": [
              {
                "condition": "waf_ec_ops_dp4_bp1 && waf_ec_ops_dp4_bp2 && waf_ec_ops_dp4_bp3",
                "risk": "NO_RISK"
              },
              {
                "condition": "!waf_ec_ops_dp4_bp1 || !waf_ec_ops_dp4_bp2 || !waf_ec_ops_dp4_bp3 || waf_ec_ops_dp4_bp4",
                "risk": "MEDIUM_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_ops_dp5",
            "title": "How do you manage clients connections to your ElastiCache clusters?",
            "description": "When operating at scale you need to understand how your clients connect with the ElastiCache cluster to manage your application operational aspects (such as response times). ",
            "choices": [
              {
                "id": "waf_ec_ops_dp5_bp1",
                "title": "Separate read from write operations and connect to the replica nodes to execute read operations.",
                "improvementPlan": {
                  "displayText": "When you separate the writes from the reads you will lose the ability to read a key immediately after writing it. Using replica nodes for read operations can be configured in your ElastiCache for Redis client library using the ElastiCache reader endpoint for cluster mode disabled. For cluster mode enabled, use the ElastiCache for Redis READONLY command. For many of the Redis client libraries, READONLY is implemented by default or via a configuration setting.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html"
                },
                "helpfulResource": {
                  "displayText": "Choosing the most appropriate connection mechanism ensures that your application does not disconnect due to connectivity errors, such as time-outs.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html"
                }
              },
              {
                "id": "waf_ec_ops_dp5_bp2",
                "title": "Use connection pooling.",
                "improvementPlan": {
                  "displayText": "Use connection pooling. Establishing a TCP connection has a cost in CPU time on both client and server sides and pooling allows you to reuse the TCP connection. To reduce connection overhead, you should use connection pooling. With a pool of connections your application can re-use and release connections as necessary, without the cost of establishing the connection. You can implement connection pooling via your Redis client library (if supported), with a Framework available for your application environment, or build it from the ground up."
                },
                "helpfulResource": {
                  "displayText": "Choosing the most appropriate connection mechanism ensures that your application does not disconnect due to connectivity errors, such as time-outs."
                }
              },
              {
                  "id": "waf_ec_ops_dp5_bp3",
                  "title": "Ensure that the socket timeout of the client is set to at least one second ",
                  "improvementPlan": {
                    "displayText": "Ensure that the socket timeout of the client is set to at least one second (vs. the typical “none” default in several clients). - Setting the timeout value too low can lead to possible timeouts when the server load is high. Setting it too high can result in your application taking a long time to detect connection issues. - Control the volume of new connections by implementing connection pooling in your client application. This reduces latency and CPU utilization needed to open and close connections, and perform a TLS handshake if TLS is enabled on the cluster.",
                    "url": "https://aws.amazon.com/blogs/database/configuring-amazon-elasticache-for-redis-for-higher-availability/"
                  },
                  "helpfulResource": {
                      "displayText": "Choosing the most appropriate connection mechanism ensures that your application does not disconnect due to connectivity errors, such as time-outs.",
                      "url": "https://aws.amazon.com/blogs/database/configuring-amazon-elasticache-for-redis-for-higher-availability/"
                  }
              },
              {
                  "id": "waf_ec_ops_dp5_bp4",
                  "title": "Using pipelining can significantly boost ingestion performance.",
                  "improvementPlan": {
                    "displayText": "Using pipelining (when your use cases allow it) can significantly boost the performance. - With pipelining you reduce the Round-Trip Time (RTT) between your application clients and the cluster and new requests can be processed even if the client has not yet read the previous responses. - With pipelining you can send multiple commands to the server without waiting for acknowledgement from the server. The downside of pipelining is that when you eventually fetch all the responses in bulk there may have been an error that you will not catch until the end. - Implement methods to retry requests when an error is returned that omits the bad request.",
                    "url": "https://redis.io/docs/manual/pipelining/"
                  },
                  "helpfulResource": {
                    "displayText": "Choosing the most appropriate connection mechanism ensures that your application does not disconnect due to connectivity errors, such as time-outs.",
                    "url": "https://redis.io/docs/manual/pipelining/"
                  }
              },
              {
                "id": "waf_ec_ops_dp5_bp5",
                "title": "None of these",
                "improvementPlan": {
                  "displayText": "Apply the recommended best practices"
  
                },
                "helpfulResource": {
                  "displayText": "Choose this if your workload does not follow these best practices."
                }
              }
  
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_ops_dp5_bp1 || !waf_ec_ops_dp5_bp2 || waf_ec_ops_dp5_bp5",
                  "risk": "HIGH_RISK"
              },
              {
                  "condition": "!waf_ec_ops_dp5_bp3 || !waf_ec_ops_dp5_bp4",
                  "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_ops_dp5_bp1 && waf_ec_ops_dp5_bp2 && waf_ec_ops_dp5_bp3 && waf_ec_ops_dp5_bp4",
                "risk": "NO_RISK"
              }
            ]
          }
        ]
      },
      {
        "id": "waf_ec_2_sec",
        "name": "Security",
        "questions": [
          {
            "id": "waf_ec_sec_dp4",
            "title": "What steps are you taking in controlling authorized access to ElastiCache data?",
            "description": "All ElastiCache clusters are designed to be accessed from Amazon EC2 instances in an Amazon Virtual Private Cloud (VPC), serverless functions (AWS Lambda), or containers (Amazon Elastic Container Service). The most encountered scenario is to access an ElastiCache cluster from an Amazon EC2 instance within the same VPC. Before you can connect to a cluster from an EC2 instance, you must authorize the EC2 instance to access the cluster. To access an ElastiCache cluster running in a VPC, it is necessary to grant network ingress to the cluster.",
            "choices": [
              {
                "id": "waf_ec_sec_dp4_bp1",
                "title": "Using separate accounts for ElastiCache clusters in production and non-production environments",
                "improvementPlan": {
                  "displayText": "Start with security and infrastructure in mind to enable your organization to build a security baseline for production and non-production environments. Organize workload including ElastiCache in separate accounts and group accounts based on production, and non-production environment, which might have different security and access requirement.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                },
                "helpfulResource": {
                  "displayText": "Folow least privileged access model for your production and non-production accounts.Manage privileges via AIM roles.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                }
              },
              {
                "id": "waf_ec_sec_dp4_bp2",
                "title": "Identify compliance requirements for data stored in ElastiCache clusters for production and non-production environments",
                "improvementPlan": {
                  "displayText": "Identify compliance requirements for production and non-production environments. Ensure that compliance requirements are met based on organizational, legal, and compliance requirements.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                },
                "helpfulResource": {
                  "displayText": "Make sure data stored in ElastiCache cluster comply with security requirements.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                }
              },
              {
                "id": "waf_ec_sec_dp4_bp3",
                "title": "Automate configuration management using CloudFormation",
                "improvementPlan": {
                  "displayText": "Eliminate manual configuration changes. CloudFormation StackSets can be used to deploy resources including ElastiCache, IAM policies, roles, and groups.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                },
                "helpfulResource": {
                  "displayText": "Automate configuration management using service or tool like CloudFormtaion and CDK help you enforce and validate secure configurations automatically.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                }
            },
            {
              "id": "waf_ec_sec_dp4_bp4",
              "title": "Latest engine version",
              "improvementPlan": {
                "displayText": "Latest engine version. The latest engine version includes the latest security and stability patches. Ensure that the latest engine version is used and patches are applied in your ElastiCache services. Enable notification for service updates",
                "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.ViewDetails.html"
              },
              "helpfulResource": {
                "displayText": "Using the latest engine version for your cluster ensures that an older engine version's known vulnerability issues have been addressed and your exposure is minimized. Enable notification for service updates. Always apply version updates to non-production environments first before applying to production services. Evaluate client application after service version update and ensure that client libraries are compatible with the new engine version. To fully take advantage of the latest engine version client libraries may need to be updated as well.",
                "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/redis-security.html"
              }
            },
            {
              "id": "waf_ec_sec_dp4_bp5",
              "title": "Change default port",
              "improvementPlan": {
                "displayText": "Change default port (6379 for ElastiCache for Redis). Default ports for many services are widely known and provide an easy traget for bad actors. Ensure that your services are not using the default ports for Memcached and Redis engines.",
                "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.ViewDetails.html"
              },
              "helpfulResource": {
                "displayText": "By changing your services's network port from the published default port to a non-default port number reduces obvious attack surfaces.",
                "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/redis-security.html"
              }
            },
            {
                "id": "waf_ec_sec_dp4_bp6",
                "title": "In-transit and at-rest encrpytion",
                "improvementPlan": {
                  "displayText": "Ensure that in-transit and at-rest encryptions are both enabled for ElastiCache clusters. Client connections need to be updated to ensure encryption in-transit is initiated for each connection. Encryption at rest is based on KSM keys. Ensure that the master key used to protect the encryption keys is in compliance with your workload needs.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                },
                "helpfulResource": {
                  "displayText": "Make sure data transmitted and stored in ElastiCache cluster comply with security requirements including encryption.",
                  "url": "https://wa.aws.amazon.com/wat.question.SEC_1.en.html"
                }
            },
              {
                "id": "waf_ec_sec_dp4_bp7",
                "title": "Security Groups in place to access the cluster",
                "improvementPlan": {
                  "displayText": "The security group associated with your cluster controls network ingress and access to the cluster. By default, a security group will not have any inbound rules defined and, therefore, no ingress path to ElastiCache. To enable this, configure an inbound rule on the security group specifying source IP address/range or source security group name, TCP type traffic and the port for your ElastiCache cluster (change default port 6379 for ElastiCache for Redis to further enhance security). While it is possible to allow a very broad set of ingress sources, like all resources within a VPC (0.0.0.0/0), it is advised to be as granular as possible in defining the inbound rules such as authorizing only inbound access from clients who's IP address belongs to a given CIDR block. Alternately it is possible to allow only clients belonging to a specific security group instead of having an IP in a CIDR block.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/accessing-elasticache.html"
                },
                "helpfulResource": {
                  "displayText": "Network ingress into the cluster is controlled via VPC security groups. A security group acts as a virtual firewall to control incoming and outgoing traffic. Inbound rules control the incoming traffic to your instance, and outbound rules control the outgoing traffic from your instance. In the case of ElastiCache, when launching a cluster, it requires associating a security group. This ensures that inbound and outbound traffic rules are in place for all nodes that make up the cluster. Additionally, ElastiCache is configured to deploy on private subnets exclusively such that they are only accessible via the VPC’s private networking.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/redis-security.html"
                }
              },
              {
                "id": "waf_ec_sec_dp4_bp8",
                "title": "Use of IAM Policies to access ElastiCache Data",
                "improvementPlan": {
                  "displayText": "AWS IAM policies can be assigned to AWS Lambda functions allowing them to access ElastiCache data. To enable this feature, create an IAM execution role with the AWSLambdaVPCAccessExecutionRole permission, then assign the role to the AWS Lambda function.",
                  "url": "https://docs.aws.amazon.com/lambda/latest/dg/services-elasticache-tutorial.html"
                },
                "helpfulResource": {
                  "displayText": "Network ingress into the cluster is controlled via VPC security groups. A security group acts as a virtual firewall to control incoming and outgoing traffic. Inbound rules control the incoming traffic to your instance, and outbound rules control the outgoing traffic from your instance. In the case of ElastiCache, when launching a cluster, it requires associating a security group. This ensures that inbound and outbound traffic rules are in place for all nodes that make up the cluster. Additionally, ElastiCache is configured to deploy on private subnets exclusively such that they are only accessible via the VPC’s private networking.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/redis-security.html"
                }
              },
              {
                  "id": "waf_ec_sec_dp4_bp9",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }                        
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp4_bp1 || !waf_ec_sec_dp4_bp2 || !waf_ec_sec_dp4_bp6 || !waf_ec_sec_dp4_bp7 || !waf_ec_sec_dp4_bp8 || waf_ec_sec_dp4_bp9",
                "risk": "HIGH_RISK"
              },
              {
                "condition": " !waf_ec_sec_dp4_bp3 || !waf_ec_sec_dp4_bp4 || !waf_ec_sec_dp4_bp5",
                "risk": "MEDIUM_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_sec_dp5",
            "title": "Do your applications require additional authorization to ElastiCache over and above networking-based controls?",
            "description": "In scenarios where it is necessary to restrict or control access to ElastiCache for Redis clusters at an individual client level, it is recommended to authenticate via the ElastiCache for Redis AUTH command. ElastiCache for Redis authentication tokens, with optional user and user group management, enable ElastiCache for Redis to require a password before allowing clients to run commands and access keys, thereby improving data plane security.",
            "choices": [
              {
                "id": "waf_ec_sec_dp5_bp1",
                "title": "Define authentication and authorization controls",
                "improvementPlan": {
                  "displayText": "For ElastiCache for Redis 6.x and higher, define authentication and authorization controls by defining user groups, users, and access strings via Role Based Access Control (RBAC). Assign users to user groups, then assign user groups to clusters. To utilize RBAC, it must be selected upon cluster creation, and in-transit encryption must be enabled. Ensure you are using a Redis client that supports TLS.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Clusters.RBAC.html"
                },
                "helpfulResource": {
                  "displayText": "To help keep your data secure, ElastiCache for Redis provides mechanisms to safeguard against unauthorized access of your data. This includes enforcing Role-Based Access Control (RBAC) AUTH, or AUTH token (password) be used by clients to connect to ElastiCache before performing authorized commands.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth-redis.html"
                }
              },
              {
                "id": "waf_ec_sec_dp5_bp2",
                "title": "Use of Authentication Tokens and Rotation of Tokens",
                "improvementPlan": {
                  "displayText": "For ElastiCache for Redis versions prior to 6.x, in addition to setting strong token/password and maintaining a strict password policy for ElastiCache for Redis AUTH, it is best practice to rotate the password/token. ElastiCache can manage up to two (2) authentication tokens at any given time per Redis User. You can also modify the cluster to explicitly require the use of authentication tokens.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html#auth-modifyng-token"
                },
                "helpfulResource": {
                  "displayText": "To help keep your data secure, ElastiCache for Redis provides mechanisms to safeguard against unauthorized access of your data. This includes enforcing Role-Based Access Control (RBAC) AUTH, or AUTH token (password) be used by clients to connect to ElastiCache before performing authorized commands.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth-redis.html"
                }
              },
              {
                  "id": "waf_ec_sec_dp5_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp5_bp1 || waf_ec_sec_dp5_bp2 || !waf_ec_sec_dp5_bp3",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_sec_dp5_bp1 || !waf_ec_sec_dp5_bp2 || waf_ec_sec_dp5_bp3",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_sec_dp5_bp1",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_sec_dp9",
            "title": "Is there a risk that commands can be executed inadvertently, causing data loss or failure?",
            "description": "There are a number of Redis commands that can have adverse impacts on operations if executed by mistake or by malicious actors.",
            "choices": [
              {
                "id": "waf_ec_sec_dp9_bp1",
                "title": "Set the rename commands parameter to rename commands that need to be effectively disabled",
                "improvementPlan": {
                  "displayText": "For your production cluster, set the “rename-commands” parameter to rename commands that need to be effectively disabled. A few ElastiCache for Redis commands to consider renaming are FLUSHALL and FLUSHDB. These commands delete all data on the cluster. The command name changes are applied immediately, and automatically propagated across all nodes in the cluster that contain the command list. There is no intervention required on your part, such as rebooting nodes. In Redis 6, when RBAC is enabled, we can use access strings to restrict disruptive commands like KEYS, FLUSHALL, FLUSHDB for a specific user.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ParameterGroups.Redis.html#ParameterGroups.Redis.5-0-3"
                },
                "helpfulResource": {
                 "displayText" : "Beginning with ElastiCache for Redis 5.0.3 on ElastiCache, you have the ability to rename certain commands that might be disruptive to your workload. Renaming the commands will prevent them from being executed on the cluster. The recommended approach for ElastiCache for Redis 6.x and higher is to set-up RBAC before renaming commands.",
                 "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ParameterGroups.html"
                }
              },
              {
                  "id": "waf_ec_sec_dp9_bp2",
                  "title": "Not in place",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }            
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp9_bp1 || waf_ec_sec_dp9_bp2",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "waf_ec_sec_dp9_bp1",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_sec_dp8",
            "title": "How do you ensure data encryption at rest with ElastiCache?",
            "description": "While ElastiCache for Redis is an in-memory data store, it is possible to encrypt any data that may be persisted (on storage) as part of standard operations of the cluster. This includes both scheduled and manual backups written to Amazon S3, as well as data saved to disk storage as a result of snapshot, sync and swap operations. Instance types in the M6g and R6g families also feature always-on, in-memory encryption.",
            "choices": [
              {
                "id": "waf_ec_sec_dp8_bp1",
                "title": "Encryption at Rest is enabled for the ElastiCache Clusters",
                "improvementPlan": {
                  "displayText": "At-rest encryption can be enabled on an ElastiCache cluster (replication group) only when it is created. An existing cluster cannot be modified to begin encrypting data at-rest. By default, ElastiCache will provide and manage the keys used in at-rest encryption.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/at-rest-encryption.html#at-rest-encryption-enable"
                },
                "helpfulResource": {
                  "displayText": "ElastiCache for Redis provides optional encryption at-rest to increase data security.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/data-protection.html"
                }
              },
              {
                "id": "waf_ec_sec_dp8_bp2",
                "title": "Leverage EC2 instance types that encrypt data while it is in memory",
                "improvementPlan": {
                  "displayText": "Leverage EC2 instance types that encrypt data while it is in memory (such as M6g or R6g). Where possible, consider managing your own keys for at-rest encryption. For more stringent data security environments, AWS Key Management Service (KMS) can be used to self-manage Customer Master Keys (CMK). Through ElastiCache integration with AWS KMS, you are able to create, own, and manage the keys used for encryption of data at rest for your ElastiCache for Redis cluster.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/at-rest-encryption.html#using-customer-managed-keys-for-elasticache-security"
                },
                "helpfulResource": {
                  "displayText": "ElastiCache for Redis provides optional encryption at-rest to increase data security.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/data-protection.html"
                }
              },
              {
                  "id": "waf_ec_sec_dp8_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp8_bp1 || waf_ec_sec_dp8_bp3",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_sec_dp8_bp2",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_sec_dp8_bp1 && waf_ec_sec_dp8_bp2",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_sec_dp6",
            "title": "How do you encrypt in-transit data with ElastiCache?",
            "description": "It is a common requirement to mitigate against data being compromised while in transit. This represents data within components of a distributed system, as well as between application clients and cluster nodes. ElastiCache for Redis supports this requirement by allowing for encrypting data in-transit between clients and cluster, and between cluster nodes themselves. Instance types in the M6g and R6g families also feature always-on, in-memory encryption.",
            "choices": [
              {
                "id": "waf_ec_sec_dp6_bp1",
                "title": "Encryption in Transit is Enabled for all ElastiCache Clusters",
                "improvementPlan": {
                  "displayText": "Please note that, due to the additional processing required for encrypting/decrypting data, implementing in-transit encryption will have some performance impact",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/in-transit-encryption.html#in-transit-encryption-enable"
                },
                "helpfulResource": {
                  "displayText": "Amazon ElastiCache in-transit encryption is an optional feature that allows you to increase the security of your data at its most vulnerable points, when it is in-transit from one location to another.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/in-transit-encryption.html#in-transit-encryption-overview"
                }
              },
              {
                  "id": "waf_ec_sec_dp6_bp2",
                  "title": "Not in place",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }  
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp6_bp1 || waf_ec_sec_dp6_bp2",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "waf_ec_sec_dp6_bp1",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_sec_dp7",
            "title": "How do you restrict access to control plane resources?",
            "description": "IAM policies and ARN enable fine-grained access controls for ElastiCache for Redis, allowing for tighter control to manage the creation, modification and deletion of ElastiCache for Redis clusters.",
            "choices": [
              {
                "id": "waf_ec_sec_dp7_bp1",
                "title": "Finer Control over which accounts can perform what actions on clusters",
                "improvementPlan": {
                  "displayText": "Manage access to Amazon ElastiCache resources by assigning specific AWS IAM policies to AWS users, allowing finer control over which user accounts can perform what actions on clusters.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/IAM.IdentityBasedPolicies.html"
                },
                "helpfulResource": {
                  "displayText": "Management of Amazon ElastiCache resources, such as replication groups, nodes, etc. can be constrained to AWS user accounts that have specific permissions based on IAM policies, improving security and reliability of resources.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/IAM.Overview.html"
                }
              },
              {
                  "id": "waf_ec_sec_dp7_bp2",
                  "title": "Not in place",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }  
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_sec_dp7_bp1 || waf_ec_sec_dp7_bp2",
                "risk": "HIGH_RISK"
              },
              {
                "condition": "waf_ec_sec_dp7_bp1",
                "risk": "NO_RISK"
              }
            ]
          }
  
        ]
      },
      {
        "id": "waf_ec_3_rel",
        "name": "Reliability",
        "questions": [
          {
            "id": "waf_ec_rel_dp7",
            "title": "How are you supporting high availability (HA) architecture deployments?",
            "description": "Understanding the high availability architecture of Amazon ElastiCache will enable you to operate in a resilient state during availability events.",
            "choices": [
              {
                "id": "waf_ec_rel_dp7_bp1",
                "title": "Define reliability needs for each type of environment you operate your clusters in",
                "improvementPlan": {
                  "displayText": "Determine the level of availability you require for your ElastiCache cluster. Different workloads have different resiliency standards, from entirely ephemeral to mission critical workloads. Define needs for each type of environment you operate such as dev, test, and production. Note that Memcached does not provide any replication mechanism and is used primarily for ephemeral workloads. ElastiCache for Redis offers HA features discussed below."
                },
                "helpfulResource": {
                  "displayText": "Architecting your ElastiCache for Redis clusters to be resilient to failures ensures higher availability for your ElastiCache deployments.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html"
                }
              },
              {
                "id": "waf_ec_rel_dp7_bp2",
                "title": "Use ElastiCache for Redis in Cluster Mode",
                "improvementPlan": {
                  "displayText": "For workloads that require HA, use ElastiCache for Redis with cluster mode enabled (CME) with a minimum of 2 replicas per shard, even for small throughput requirement workloads that require only 1 shard. For cluster mode enabled, multi-AZ is enabled automatically : Multi-AZ minimizes downtime by performing automatic failovers from primary node to replicas, in case of any planned or unplanned maintenance. For cluster mode enabled, a minimum of three shards provides improved availability by providing faster recovery during both planned and unplanned failovers. Set up two or more replicas across Availability Zones: Having two replicas provides improved read scalability and also read availability in scenarios where one replica is undergoing maintenance. Use Graviton2-based node types (default nodes in most regions): Amazon ElastiCache for Redis has added optimized performance on these nodes. As a result, you get better replication and synchronization performance, resulting in overall improved availability. Monitor and right-size to deal with anticipated traffic peaks: under heavy load, the ElastiCache for Redis engine may become unresponsive, which affects availability. BytesUsedForCache and DatabaseMemoryUsagePercentage are good indicators of your memory usage, whereas ReplicationLag is an indicator of your replication health based on your write rate. You can use these metrics to trigger cluster scaling. Avoid maintenance and upgrades during peak usage: Reduced write loads improve failover reliability and minimize application impact. Ensure client-side resiliency by testing with the Failover API prior to a production failover event",
                  "url": "https://aws.amazon.com/blogs/database/configuring-amazon-elasticache-for-redis-for-higher-availability/"
                },
                "helpfulResource": {
                  "displayText": "Architecting your ElastiCache clusters to be resilient to failures ensures higher availability for your ElastiCache deployments.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html"
                }
              },
              {
                  "id": "waf_ec_rel_dp7_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_rel_dp7_bp1 || waf_ec_rel_dp7_bp3",
                  "risk": "HIGH_RISK"
              },
              {
                  "condition": "!waf_ec_rel_dp7_bp2",
                  "risk": "MEDIUM_RISK"
              },
              {
              "condition": "waf_ec_rel_dp7_bp1 && waf_ec_rel_dp7_bp2",
              "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_rel_dp8",
            "title": "How are you meeting your Recovery Point Objectives (RPOs) with ElastiCache?",
            "description": "Understand workload RPO to inform decisions on ElastiCache backup and recovery strategies.",
            "choices": [
              {
                "id": "waf_ec_rel_dp8_bp1",
                "title": "Document the RPO of your ElastiCache deployments.",
                "improvementPlan": {
                  "displayText": "Understand and document the RPO of your ElastiCache deployments. Be aware that Memcached does not offer any backup processes. Review the capabilities of ElastiCache Backup and Restore features.",
                  "url": "https://aws.amazon.com/blogs/aws/backup-and-restore-elasticache-redis-nodes/"
                },
                "helpfulResource": {
                  "displayText": "Having an in-place RPO strategy can improve business continuity in the event of a disaster recovery scenarios. Designing your backup and restore policies can help you meet your Recovery Point Objectives (RPO) for your ElastiCache data. ElastiCache for Redis offers snapshot capabilities which are stored in Amazon S3, along with a configurable retention policy. These snapshots are taken during a defined backup window, and handled by the service automatically. If your workload requires additional backup granularity, you have the option to create up to 20 manual backups per day, which can also be called via API on a scheduled basis. Manually created backups do not have a service retention policy and can be kept indefinitely.",
                  "url": "https://aws.amazon.com/blogs/aws/backup-and-restore-elasticache-redis-nodes/"
                }
              },
              {
                "id": "waf_ec_rel_dp8_bp2",
                "title": "Well-communicated process in place for backing up your cluster and Scheduled backups in place",
                "improvementPlan": {
                  "displayText": "Have a well-communicated process in place for backing up your cluster. Initiate manual backups on an as-needed basis. Review retention policies for automatic backups. Note that manual backups will be retained indefinitely. Schedule your automatic backups during periods of low usage. Perform backup operations against read-replicas to ensure you minimize the impact on cluster performance.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/backups.html"
                },
                "helpfulResource": {
                  "displayText": "Having an in-place RPO strategy can improve business continuity in the event of a disaster recovery scenarios. Designing your backup and restore policies can help you meet your Recovery Point Objectives (RPO) for your ElastiCache data. ElastiCache for Redis offers snapshot capabilities which are stored in Amazon S3, along with a configurable retention policy. These snapshots are taken during a defined backup window, and handled by the service automatically. If your workload requires additional backup granularity, you have the option to create up to 20 manual backups per day, which can also be called via API on a scheduled basis. Manually created backups do not have a service retention policy and can be kept indefinitely.",
                  "url": "https://aws.amazon.com/blogs/aws/backup-and-restore-elasticache-redis-nodes/"
                }
              },
              {
                  "id": "waf_ec_rel_dp8_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_rel_dp8_bp1 || waf_ec_rel_dp8_bp3",
                "risk": "HIGH_RISK"
              },
              {
                  "condition": "!waf_ec_rel_dp8_bp2",
                  "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_rel_dp8_bp1 && waf_ec_rel_dp8_bp2",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_rel_dp9",
            "title": "How do you support disaster recovery (DR) requirements?",
            "description": "Disaster recovery is an important aspect of any workload planning. ElastiCache for Redis offers several options to implement disaster recovery based on workload resilience requirements. With Amazon ElastiCache for Redis Global Datastore, you can write to your ElastiCache for Redis cluster in one region and have the data available to be read from two other cross-region replica clusters, thereby enabling low-latency reads and disaster recovery across regions.",
            "choices": [
              {
                "id": "waf_ec_rel_dp9_bp1",
                "title": "Do you have Documented DR Strategies for your workloads",
                "improvementPlan": {
                  "displayText": "Develop and document DR strategies for all your ElastiCache workloads. Understand the DR options available on a regional and multi-region level : Multi-AZ Deployments, Global Datastore.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html"
                },
                "helpfulResource": {
                  "displayText": "Understanding and planning for a variety of disaster scenarios can ensure business continuity. DR strategies must be balanced against cost, performance impact, and data loss potential.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/FaultTolerance.html"
                }
              },
              {
                "id": "waf_ec_rel_dp9_bp2",
                "title": "Global Stores are Enabled",
                "improvementPlan": {
                  "displayText": "Enable Global Datastore - Have a plan to promote a secondary region in case of primary degradation. Test multi-region cluster promotion process prior to deploying in production. Monitor ReplicationLag metric to understand potential impact of data loss during failover events.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Redis-Global-Datastore.html"
                },
                "helpfulResource": {
                  "displayText": "Understanding and planning for a variety of disaster scenarios can ensure business continuity. DR strategies must be balanced against cost, performance impact, and data loss potential.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/FaultTolerance.html"
                }
              },
              {
                  "id": "waf_ec_rel_dp9_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_rel_dp9_bp1 || waf_ec_rel_dp9_bp3",
                  "risk": "HIGH_RISK"
              },
              {
                  "condition": "!waf_ec_rel_dp9_bp2",
                  "risk": "MEDIUM_RISK"
              },
              {
              "condition": "waf_ec_rel_dp9_bp1 && waf_ec_rel_dp9_bp2",
              "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_rel_dp10",
            "title": "How do you effectively plan for failovers?",
            "description": "Enabling multi-AZ with automatic failovers is an ElastiCache best practice. In certain cases, ElastiCache for Redis replaces primary nodes as part of service operations. Examples include planned maintenance events and the unlikely case of a node failure or availability zone issue. Successful failovers rely on both ElastiCache and your client library configuration.",
            "choices": [
              {
                "id": "waf_ec_rel_dp10_bp1",
                "title": "Mechamisms in place based on cluster mode to notify clients for any changes in cluster availability",
                "improvementPlan": {
                  "displayText": "For cluster mode disabled, use timeouts so your clients detect if it needs to disconnect from the old primary node and reconnect to the new primary node, using the updated primary endpoint IP address. For cluster mode enabled, the client library is responsible for detecting changes in the underlying cluster topology. This is accomplished most often by configuration settings in the Redis client library, which also allows you to configure the frequency and the method of refresh. Each client library offers its own settings and more details are available in their corresponding documentation.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html"
                },
                "helpfulResource": {
                  "displayText": "Following best practices for ElastiCache failovers in conjunction with your specific Redis client library helps you minimize potential downtime during failover events.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html"
                }
              },
              {
                "id": "waf_ec_rel_dp10_bp2",
                "title": "Healthy replication environment between the primary and the replica nodes",
                "improvementPlan": {
                  "displayText": "Successful failovers depend on a healthy replication environment between the primary and the replica nodes. High replication lag, or high write volumes, can result in missing data in the new primary node during a failover process. Actively explore replication metrics to understand the underlying reasons for replication lag.",
                  "url": "https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/"
                },
                "helpfulResource": {
                  "displayText": "Following best practices for ElastiCache failovers in conjunction with your specific Redis client library helps you minimize potential downtime during failover events.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html"
                }
              },
              {
                "id": "waf_ec_rel_dp10_bp3",
                "title": "Validate the responsiveness of your application during failover",
                "improvementPlan": {
                  "displayText": "Regularly validate the responsiveness of your application during failover using the ElastiCache Test Failover API. ",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html#auto-failover-test"
                },
                "helpfulResource": {
                  "displayText": "Following best practices for ElastiCache failovers in conjunction with your specific Redis client library helps you minimize potential downtime during failover events.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Replication.html"
                }
              },
              {
                  "id": "waf_ec_rel_dp10_bp4",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }            
            ],
            "riskRules": [
              {
                "condition": "!waf_ec_rel_dp10_bp1 || !waf_ec_rel_dp10_bp2 || waf_ec_rel_dp10_bp4",
                "risk": "HIGH_RISK"
              },
              {
                  "condition": "!waf_ec_rel_dp10_bp3",
                  "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_rel_dp10_bp1 && waf_ec_rel_dp10_bp2 && waf_ec_rel_dp10_bp3",
                "risk": "NO_RISK"
              }
            ]
          }
        ]
      },
      {
        "id": "waf_ec_4_perf",
        "name": "Performance efficiency",
        "questions": [
          {
            "id": "waf_ec_perf_dp9",
            "title": "How do you monitor the performance of your Amazon ElastiCache cluster?",
            "description": "HYou need to understand the existing monitoring metrics to identify current utilization. Proper monitoring can help identify potential bottlenecks impacting the performance of your cluster.",
            "choices": [
              {
                "id": "waf_ec_perf_dp9_bp1",
                "title": "Baseline performance testing using a subset of your workload",
                "improvementPlan": {
                  "displayText": "Baseline performance testing using a subset of your workload. You should monitor performance of the actual workload using mechanisms such as load testing. Monitor the CloudWatch metrics while running these tests to gain an understanding of metrics available, and to establish a performance baseline.",
                  "url": "https://redis.io/docs/management/optimization/benchmarks/"
                },
                "helpfulResource": {
                  "displayText": "Understanding the metrics associated with your cluster can help inform optimization techniques that can lead to reduced latency and increased throughput.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                }
              },
              {
                "id": "waf_ec_perf_dp9_bp2",
                "title": "Do you limit the ability of users to run blocking commands on production clusters",
                "improvementPlan": {
                  "displayText": "For ElastiCache for Redis workloads, rename expensive commands, such as KEYS and DEL to limit the ability of users to run blocking commands on production clusters. ElastiCache for Redis workloads running engine 6.x, can leverage role-based access control to restrict certain commands. Access to the commands can be controlled by creating Users and User Groups with the AWS Console or CLI, and associating the User Groups to an ElastiCache for Redis cluster. In Redis 6, when RBAC is enabled, we can use '-@dangerous' and it will disallow expensive commands like KEYS, MONITOR, SORT, etc. for that user. For engine version 5.x, rename commands using the rename-commands parameter on the Amazon ElastiCache for Redis cluster parameter group."
                },
                "helpfulResource": {
                  "displayText": "Understanding the metrics associated with your cluster can help inform optimization techniques that can lead to reduced latency and increased throughput.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                }
              },
              {
                "id": "waf_ec_perf_dp9_bp3",
                "title": "Analyze slow queries and look for optimization techniques.",
                "improvementPlan": {
                  "displayText": "For ElastiCache for Redis workloads, learn more about your queries by analyzing the SlowLog. For example, you can use the following command, 'redis-cli slowlog get 10' to show last 10 commands which exceeded latency thresholds. Certain queries can be performed more efficiently using complex ElastiCache for Redis data structures. As an example, for numerical style range lookups, an application can implement simple numerical indexes with Sorted Sets. Managing these indexes can reduce scans performed on the data set, and return data with greater performance efficiency. For ElastiCache for Redis workloads, redis-benchmark provides a simple interface for testing the performance of different commands using user defined inputs like number of clients, and size of data. Since Memcached only supports simple key level commands, consider building additional keys as indexes to avoid iterating through the key space to serve client queries.",
                  "url": "https://redis.io/commands/slowlog/"
                },
                "helpfulResource": {
                  "displayText": "Understanding the metrics associated with your cluster can help inform optimization techniques that can lead to reduced latency and increased throughput.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                }
              },
              {
                  "id": "waf_ec_perf_dp9_bp4",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_perf_dp9_bp1 || waf_ec_perf_dp9_bp4",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_perf_dp9_bp2 || !waf_ec_perf_dp9_bp3",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_perf_dp9_bp1 && waf_ec_perf_dp9_bp2 && waf_ec_perf_dp9_bp3",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_perf_dp10",
            "title": "How are you distributing work across your ElastiCache Cluster nodes?",
            "description": "The way your application connects to Amazon ElastiCache nodes can impact the performance and scalability of the cluster.",
            "choices": [
              {
                "id": "waf_ec_perf_dp10_bp1",
                "title": "Have clients connect to the proper ElastiCache endpoint",
                "improvementPlan": {
                  "displayText": "Have clients connect to the proper ElastiCache endpoint. Amazon ElastiCache for Redis implements different endpoints based on the cluster mode in use. For cluster mode enabled, ElastiCache will provide a configuration endpoint. For cluster mode disabled, ElastiCache provides a primary endpoint, typically used for writes, and a reader endpoint for balancing reads across replicas. Implementing these endpoints correctly will results in better performance, and easier scaling operations. Avoid connecting to individual nodes or IP addresses unless there is a specific requirement to do so. For multi-node Memcached clusters, the cluster provides a configuration endpoint which supports Auto Discovery. It is recommended to use a hashing algorithm to distribute work evenly across the cache nodes. Many Memcached client libraries implement consistent hashing. Check the documentation for the library you are using to see if it supports consistent hashing and how to implement it.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Endpoints.html"
                },
                "helpfulResource": {
                  "displayText": "Making proper use of the available nodes in the cluster will ensure that work is distributed across the available resources. The following techniques help avoid idle resources as well.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/BestPractices.LoadBalancing.html"
                }
              },
              {
                "id": "waf_ec_perf_dp10_bp2",
                "title": "Take advantage of ElastiCache for Redis cluster mode enabled to improve scalability",
                "improvementPlan": {
                  "displayText": "Take advantage of ElastiCache for Redis cluster mode enabled to improve scalability. ElastiCache for Redis (cluster mode enabled) clusters support online scaling operations to help distribute data dynamically across shards. It also provides the ability to add or remove shards depending on your workload requirements. Using the Configuration Endpoint will ensure your cluster-aware clients can adjust to changes in the cluster topology. You may also rebalance the cluster by moving hashslots between available shards in your ElastiCache for Redis (cluster mode enabled) cluster. This helps distribute data more efficiently across available shards.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/redis-cluster-resharding-online.html"
                },
                "helpfulResource": {
                  "displayText": "Making proper use of the available nodes in the cluster will ensure that work is distributed across the available resources. The following techniques help avoid idle resources for ElastiCache for Memcached clusters.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/BestPractices.LoadBalancing.html"
                }
              },
              {
                "id": "waf_ec_perf_dp10_bp3",
                "title": "Implement a strategy for identifying and remediating hot keys in your workload.",
                "improvementPlan": {
                  "displayText": "Implement a strategy for identifying and remediating hot keys in your workload. Consider the impact of the Redis stream data type. A stream is a key and resides on a single node. A stream has the potential to utilize more network capacity and memory than other data types and can cause a disproportionate use of that node. Hot keys in the workload can impact performance of the node in use. For ElastiCache for Redis workloads, you can detect hot keys using redis-cli --hotkeys if an LFU max-memory policy is in place. Consider writing to multiple hot keys across multiple nodes to distribute access to them more evenly, adding a random identifier for each key (for instance, with 1 hot key that is replicated 10 times, use 'KEYNAME-X' where X is a random number 1 through 10). This approach requires the client to write to multiple primary nodes (the Redis node itself will not provide this functionality) and to maintain a list of key names to read from in addition to the original key name. ElastiCache for Redis version 6 supports server-assisted client-side caching. This enables applications to wait for changes to a key before making network calls back to ElastiCache.",
                  "url": "https://redis.io/docs/manual/client-side-caching/"
                },
                "helpfulResource": {
                  "displayText": "Making proper use of the available nodes in the cluster will ensure that work is distributed across the available resources. The following techniques help avoid idle resources as well.",
                  "url": "https://docs.aws.amazon.com/wellarchitected/latest/analytics-lens/best-practice-10-3.html"
                }
              },
              {
                  "id": "waf_ec_perf_dp10_bp4",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_perf_dp10_bp1 || waf_ec_perf_dp10_bp4",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_perf_dp10_bp2 || !waf_ec_perf_dp10_bp3",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_perf_dp10_bp1 && waf_ec_perf_dp10_bp2 && waf_ec_perf_dp10_bp3",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_perf_dp11",
            "title": "For caching workloads, how do you track and report the effectiveness and performance of your cache?",
            "description": "Caching is a commonly encountered workload on ElastiCache and it is important that you understand how to manage the effectiveness and performance of your cache.",
            "choices": [
              {
                "id": "waf_ec_perf_dp11_bp1",
                "title": "Measure and track over time the cache-hits ratio and its efficiency",
                "improvementPlan": {
                  "displayText": "Measure and track over time the cache-hits ratio. The efficiency of your cache is determined by its 'cache hits ratio'. The cache hits ratio is defined by the total of key hits divided by the total hits and misses. The closer to 1 the ratio is, the more effective your cache is. A low cache hits ratio is caused by the volume of cache misses. Cache misses occur when the requested key is not found in the cache. A key is not in the cache because it has been evicted, deleted, has expired, or has never existed. Understand why keys are not in cache and develop appropriate strategies to have them in cache.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.Redis.html"
                },
                "helpfulResource": {
                  "displayText": "Your application may show signs of sluggish performance. Your ability to use cache specific metrics to inform your decision on how to increase app performance is critical for your cache workload.",
                  "url": "https://d0.awsstatic.com/whitepapers/performance-at-scale-with-amazon-elasticache.pdf"
                }
              },
              {
                "id": "waf_ec_perf_dp11_bp2",
                "title": "Measure and collect your application cache performance in conjunction with latency and CPU utilization values ",
                "improvementPlan": {
                  "displayText": "Measure and collect your application cache performance in conjunction with latency and CPU utilization values to understand whether you need to make adjustments to your time-to-live or other application components. ElastiCache provides a set of CloudWatch metrics for aggregated latencies for each data structure. These latency metrics are calculated using the commandstats statistic from the ElastiCache for Redis INFO command and do not include the network and I/O time. This is only the time consumed by ElastiCache for Redis to process the operations.",
                  "url": "https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/"
                },
                "helpfulResource": {
                  "displayText": "Your application may show signs of sluggish performance. Your ability to use cache specific metrics to inform your decision on how to increase app performance is critical for your cache workload.",
                  "url": "https://d0.awsstatic.com/whitepapers/performance-at-scale-with-amazon-elasticache.pdf"
                }
              },
              {
                "id": "waf_ec_perf_dp11_bp3",
                "title": "Caching Strategies in place and matches the workload needs across all clusters",
                "improvementPlan": {
                  "displayText": "Choose the right caching strategy for your needs. A low cache hits ratio is caused by the volume of cache misses. If your workload is designed to have low volume of cache misses (such as a write-through cache), it is best to conduct reviews of your caching strategies and apply the most appropriate resolutions for your workload, such as query instrumentation to measure memory and performance. The actual strategies you use to implement for populating and maintaining your cache depend on what data your clients need to cache and the access patterns to that data. For example, it is unlikely that you will use the same strategy to cache adhoc Amazon Neptune queries as well as proactively cache changes as they occur in Amazon RDS.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html"
                },
                "helpfulResource": {
                  "displayText": "Your application may show signs of sluggish performance. Your ability to use cache specific metrics to inform your decision on how to increase app performance is critical for your cache workload.",
                  "url": "https://d0.awsstatic.com/whitepapers/performance-at-scale-with-amazon-elasticache.pdf"
                }
              },
              {
                  "id": "waf_ec_perf_dp11_bp4",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
                }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_perf_dp11_bp1 || !waf_ec_perf_dp11_bp2 || waf_ec_perf_dp11_bp4",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_perf_dp11_bp3",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_perf_dp11_bp1 && waf_ec_perf_dp11_bp2 && waf_ec_perf_dp11_bp3",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_perf_dp12",
            "title": "How does your application optimize the use of networking resources and connections?",
            "description": "ElastiCache for Redis and Memcached are supported by many application clients, and implementations may vary. You need to understand the networking and connection management in place to analyze potential performance impact.",
            "choices": [
              {
                "id": "waf_ec_perf_dp12_bp1",
                "title": "Proactively manage connections to your ElastiCache cluster",
                "improvementPlan": {
                  "displayText": "Proactively manage connections to your ElastiCache cluster. Connection pooling in the application reduces the amount of overhead on the cluster and client created by opening and closing connections. Monitor connection behavior in Amazon CloudWatch using CurrConnections and NewConnections. Avoid connection leaking by properly closing client connections where appropriate. Connection management strategies include properly closing connections that are not in use, and setting connection time-outs. For Memcached workloads, there is a configurable amount of memory reserved for handling connections called, memcached_connections_overhead.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.Redis.html"
                },
                "helpfulResource": {
                  "displayText": "Efficient use of networking resources can improve the performance efficiency of your cluster."
                }
              },
              {
                "id": "waf_ec_perf_dp12_bp2",
                "title": "Mechanisms to Reduce network latency in your workload ",
                "improvementPlan": {
                  "displayText": "Reduce network latency in your workload by leveraging Amazon ElastiCache for Redis. If your application is geographically distributed, consider leveraging ElastiCache for Redis Global Datastore for low latency geo-local reads. Amazon ElastiCache for Redis supports Enhanced IO handling to off-load network processing to available vCPUs on node types with 4 or more vCPUs. Amazon ElastiCache for Redis supports Redis pipelines which allows clients to send commands to the cluster without waiting for a response. This can reduce round-trip latency for grouped commands.",
                  "url": "https://aws.amazon.com/about-aws/whats-new/2019/03/amazon-elasticache-for-redis-503-enhances-io-handling-to-boost-performance/"
                },
                "helpfulResource": {
                  "displayText": "Efficient use of networking resources can improve the performance efficiency of your cluster."
                }
              },
              {
                "id": "waf_ec_perf_dp12_bp3",
                "title": "Compress large objects to reduce memory, and improve network throughput",
                "improvementPlan": {
                  "displayText": "Compress large objects to reduce memory, and improve network throughput. - Data compression can reduce the amount of network throughput required (Gbps), but increases the amount of work on the application to compress and decompress data. - Compression also reduces the amount of memory consumed by keys. - Based on your application needs, consider the trade-offs between compression ratio and compression speed."
                },
                "helpfulResource": {
                  "displayText": "Efficient use of networking resources can improve the performance efficiency of your cluster."
                }
              },
              {
                  "id": "waf_ec_perf_dp12_bp4",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_perf_dp12_bp1 || waf_ec_perf_dp12_bp4",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_perf_dp12_bp2 || !waf_ec_perf_dp12_bp3",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_perf_dp12_bp1 && waf_ec_perf_dp12_bp2 && waf_ec_perf_dp12_bp3",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_perf_dp13",
            "title": "How do you manage key deletion and/or eviction?",
            "description": "Workloads have different requirements and expected behavior when a cluster node is approaching memory consumption limits. Amazon ElastiCache for Redis has different policies for handling these situations.",
            "choices": [
              {
                "id": "waf_ec_perf_dp13_bp1",
                "title": "Identify an appropriate max-memory policy to control if and how evictions are performed on the cluster",
                "improvementPlan": {
                  "displayText": "Evaluate which policy to apply. Identify an appropriate max-memory policy to control if and how evictions are performed on the cluster. Eviction occurs when the max-memory on the cluster is consumed and a policy is in place to allow eviction. The behavior of the cluster in this situation depends on the eviction policy specified. This policy can be managed using the maxmemory-policy on the ElastiCache for Redis cluster parameter group. The default policy volatile-lru frees up memory by evicting keys with a set expiration time (TTL value). Least frequently used (LFU) and least recently used (LRU) policies remove keys based on usage. For Memcached workloads, there is a default LRU policy in place controlling evictions on each node. The number of evictions on your Amazon ElastiCache cluster can be monitored using the Evictions metric on Amazon CloudWatch.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/ParameterGroups.Redis.html"
                },
                "helpfulResource": {
                  "displayText": "Proper management of available memory, and understanding of eviction policies will help ensure awareness of cluster behavior when instance memory limits are exceeded."
                }
              },
              {
                "id": "waf_ec_perf_dp13_bp2",
                "title": "Standardize delete behavior to control performance impact on your cluster to avoid unexpected performance bottlenecks",
                "improvementPlan": {
                  "displayText": "Standardize delete behavior to control performance impact on your cluster to avoid unexpected performance bottlenecks. For ElastiCache for Redis workloads, when explicitly removing keys from the cluster, 'UNLINK' is preferred over 'DEL' as it removes the specified keys asynchrounously whereas 'DEL' runs in the foreground and can block the Redis engine. For ElastiCache for Redis 6.x workloads, the behavior of the DEL command can be modified in the parameter group using lazyfree-lazy-user-del parameter.",
                  "url": "https://redis.io/commands/unlink/"
                },
                "helpfulResource": {
                  "displayText": "Proper management of available memory, and understanding of eviction policies will help ensure awareness of cluster behavior when instance memory limits are exceeded."
                }
              },
              {
                  "id": "waf_ec_perf_dp13_bp3",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
              }
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_perf_dp13_bp1 || waf_ec_perf_dp13_bp3",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_perf_dp13_bp2",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_perf_dp13_bp1 && waf_ec_perf_dp13_bp2",
                "risk": "NO_RISK"
              }
            ]
          }                
        ]
      },
      {
        "id": "waf_ec_5_cost",
        "name": "Cost optimization",
        "questions": [
          {
            "id": "waf_ec_cost_dp12",
            "title": "How do you identify and track costs associated with your ElastiCache resources?",
            "description": "Understanding cost metrics requires the participation and collaboration of multiple teams: software engineering, data management, product owners, finance, and leadership. Identifying key cost drivers requires all involved parties understand service usage control levers and cost management trade-offs and it is frequently the key difference between successful and less successful cost optimization efforts. Ensuring you have processes and tools in place to track resources created from development to production and retirement helps you manage the costs associated with ElastiCache.",
            "choices": [
              {
                "id": "waf_ec_cost_dp12_bp1",
                "title": "Do you have a Cloud Center of Excellence or mechanisms in place to define, track and act on cost metrics",
                "improvementPlan": {
                  "displayText": "Institute a Cloud Center of Excellence (CCoE) with one of its founding charters to own defining, tracking, and taking action on metrics around your organization's ElastiCache usage. If a CCoE exists and functions, ensure that it knows how to read and track costs associated with ElastiCache. When resources are created, use IAM roles and policies to validate that only specific teams and groups can instantiate resources. This ensures that costs are associated with business outcomes and a clear line of accountability is established, from a cost perspective. CCoE should identify, define, and publish cost metrics that are updated on a regular -monthly- basis around key ElastiCache usage across categorical data such as: (1) Types of nodes used and their attributes: standard vs. memory optimized, on-demand vs. reserved instances, regions and availability zones (2) Types of environments: free, dev, testing, and production (3) Backup storage and retention strategies (4) Data transfer within and across regions. Instances running on Amazon Outposts CCoE consists of a cross-functional team with non-exclusive representation from software engineering, data management, product team, finance, and leadership teams in your organization.",
                  "url": "https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-foundation/cloud-center-of-excellence.html"
                },
                "helpfulResource": {
                  "displayText": "CCoE consists of a cross-functional team with non-exclusive representation from software engineering, data management, product team, finance, and leadership teams in your organization.",
                  "url": "https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-foundation/cloud-center-of-excellence.html"
                }
              },
              {
                "id": "waf_ec_cost_dp12_bp2",
                "title": "Use of cost allocation tags to track costs at a low level of granularity",
                "improvementPlan": {
                  "displayText": "Use cost allocation tags to track costs at a low level of granularity. Use AWS Cost Management to visualize, understand, and manage your AWS costs and usage over time. Use tags to organize your resources, and cost allocation tags to track your AWS costs on a detailed level. After you activate cost allocation tags, AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. AWS provides two types of cost allocation tags, an AWS generated tags and user-defined tags. AWS defines, creates, and applies the AWS generated tags for you, and you define, create, and apply user-defined tags. You must activate both types of tags separately before they can appear in Cost Management or on a cost allocation report. Use cost allocation tags to organize your AWS bill to reflect your own cost structure. When you add cost allocation tags to your resources in Amazon ElastiCache, you will be able to track costs by grouping expenses on your invoices by resource tag values. You should consider combining tags to track costs at a greater level of detail.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Tagging.html"
                },
                "helpfulResource": {
                  "displayText": "Use tags to organize your resources, and cost allocation tags to track your AWS costs on a detailed level. After you activate cost allocation tags, AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. AWS provides two types of cost allocation tags, an AWS generated tags and user-defined tags. AWS defines, creates, and applies the AWS generated tags for you, and you define, create, and apply user-defined tags. You must activate both types of tags separately before they can appear in Cost Management or on a cost allocation report",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Tagging.html"
                }
              },
              {
                "id": "waf_ec_cost_dp12_bp3",
                "title": "Does your monitoring include both business and operational metrics",
                "improvementPlan": {
                  "displayText": "Connect ElastiCache cost to metrics that reach across the organization. Consider business metrics as well as operational metrics like latency - what concepts in your business model are understandable across roles? The metrics need to be understandable by as many roles as possible in the organization. Examples - simultaneous served users, max and average latency per operation and user, user engagement scores, user return rates/week, session length/user, abandonment rate, cache hit rate, and keys tracked",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                },
                "helpfulResource": {
                  "displayText": "Consider business metrics as well as operational metrics like latency - what concepts in your business model are understandable across roles? The metrics need to be understandable by as many roles as possible in the organization",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                }
              },
              {
                "id": "waf_ec_cost_dp12_bp4",
                "title": "Maintain up-to-date architectural and operational visibility on metrics and costs",
                "improvementPlan": {
                  "displayText": "Maintain up-to-date architectural and operational visibility on metrics and costs across the entire application that uses ElastiCache. Understand your entire solution ecosystem, ElastiCache tends to be part of a full ecosystem of AWS services in their technology set, from clients to API Gateway, Redshift, and QuickSight for reporting tools (for instance). Map components of your solution from clients, connections, security, in-memory operations, storage, resource automation, data access and management, on your architecture diagram. Each layer connects to the entire solution and has its own needs and capabilities that add to and/or help you manage the overall cost. Your diagram should include the use of compute, networking, storage, lifecycle policies, metrics gathering as well as the operational and functional ElastiCache elements of your application. The requirements of your application are likely to evolve over time and it is essential that you continue to maintain and document your understanding of the underlying components as well as your primary functional objectives in order to remain proactive in your application cost management. Executive support for visibility, accountability, prioritization, and resources is crucial to you having an effective cost management strategy for your ElastiCache.",
                  "url": "https://docs.aws.amazon.com/whitepapers/latest/cost-management/introduction.html"
                },
                "helpfulResource": {
                  "displayText": "Understand your entire solution ecosystem, ElastiCache tends to be part of a full ecosystem of AWS services in their technology set, from clients to API Gateway, Redshift, and QuickSight for reporting tools (for instance). Executive support for visibility, accountability, prioritization, and resources is crucial to you having an effective cost management strategy for your ElastiCache.",
                  "url": "https://docs.aws.amazon.com/whitepapers/latest/cost-management/introduction.html"
                }
              },
              {
                  "id": "waf_ec_cost_dp12_bp5",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
                }            
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_cost_dp12_bp1 || !waf_ec_cost_dp12_bp2 || waf_ec_cost_dp12_bp5",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_cost_dp12_bp3 || !waf_ec_cost_dp12_bp4",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_cost_dp12_bp1 && waf_ec_cost_dp12_bp2 && waf_ec_cost_dp12_bp3 && waf_ec_cost_dp12_bp4",
                "risk": "NO_RISK"
              }
            ]
          },
          {
            "id": "waf_ec_cost_dp13",
            "title": "How do you use continuous monitoring tools to help you optimize the costs associated with your ElastiCache resources?",
            "description": "You need to aim for a proper balance between your ElastiCache cost and application performance metrics. Amazon CloudWatch provides visibility into key operational metrics that can help you assess whether your ElastiCache resources are over or under utilized, relative to your needs. From a cost optimization perspective, you need to understand when you are overprovisioned and be able to develop appropriate mechanisms to resize your ElastiCache resources while maintaining your operational, availability, resilience, and performance needs. ",
            "choices": [
              {
                "id": "waf_ec_cost_dp13_bp1",
                "title": "Use CloudWatch to monitor your ElastiCache clusters and analyze how these metrics relate to your AWS Cost Explorer dashboards",
                "improvementPlan": {
                  "displayText": "ElastiCache performance metrics (CPUUtilization, EngineUtilization, SwapUsage, CurrConnections, and Evictions) may indicate that you need to scale up/down (use larger/smaller cache node types) or in/out (add more/less shards). Understand the cost implications of scaling decisions by creating a playbook matrix that estimates the additional cost and the min and max lengths of time required to meet your application performance thresholds.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.WhichShouldIMonitor.html"
                },
                "helpfulResource": {
                  "displayText": "ElastiCache performance metrics (CPUUtilization, EngineUtilization, SwapUsage, CurrConnections, and Evictions) may indicate that you need to scale up/down (use larger/smaller cache node types) or in/out (add more/less shards). Understand the cost implications of scaling decisions by creating a playbook matrix that estimates the additional cost and the min and max lengths of time required to meet your application performance thresholds.",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.html"
                }
              },
              {
                "id": "waf_ec_cost_dp13_bp2",
                "title": "Understand and document your backup strategy and cost implications.",
                "improvementPlan": {
                  "displayText": "With ElastiCache, the backups are stored in Amazon S3, which provides durable storage. You need to understand the cost implications in relation to your ability to recover from failures.Enable automatic backups that will delete backup files that are past the retention limit",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/backups-automatic.html"
                },
                "helpfulResource": {
                  "displayText": "With ElastiCache, the backups are stored in Amazon S3, which provides durable storage. You need to understand the cost implications in relation to your ability to recover from failures.Enable automatic backups that will delete backup files that are past the retention limit",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/backups-automatic.html"
                }
              },
              {
                "id": "waf_ec_cost_dp13_bp3",
                "title": "Use Reserved Nodes as a deliberate strategy to manage costs for workloads that are well understood and documented",
                "improvementPlan": {
                  "displayText": "Use Reserved Nodes for your instances as a deliberate strategy to manage costs for workloads that are well understood and documented. Reserved nodes are charged an up front fee that depends upon the node type and the length of reservation—one or three years. This charge is much less than the hourly usage charge that you incur with On-Demand nodes",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html"
                },
                "helpfulResource": {
                  "displayText": "Use Reserved Nodes for your instances as a deliberate strategy to manage costs for workloads that are well understood and documented. Reserved nodes are charged an up front fee that depends upon the node type and the length of reservation—one or three years. This charge is much less than the hourly usage charge that you incur with On-Demand nodes",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.html"
                }
              },
              {
                "id": "waf_ec_cost_dp13_bp4",
                "title": "Use Data Tiering instance types as a deliberate strategy to manage costs for workloads that are well understood and documented",
                "improvementPlan": {
                  "displayText": "Use Data Tiering Nodes (where available) for your instances as a deliberate strategy to manage costs for workloads that are well understood and documented. Use data tiering for Amazon ElastiCache for Redis as a lower cost way to scale your clusters to up to hundreds of terabytes of capacity. Data tiering provides a new price-performance option for Redis workloads by utilizing lower-cost solid state drives (SSDs) in each cluster node in addition to storing data in memory. It is ideal for workloads that access up to 20% of their overall dataset regularly, and for applications that can tolerate additional latency when accessing data on SSD. ",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/data-tiering.html"
                },
                "helpfulResource": {
                  "displayText": "Use Data Tiering Nodes (where available) for your instances as a deliberate strategy to manage costs for workloads that are well understood and documented. ElastiCache data tiering is available when using Redis version 6.2 and above on Graviton2-based R6gd nodes. R6gd nodes have nearly 5x more total capacity (memory + SSD) and can help you achieve over 60% savings when running at maximum utilization compared to R6g nodes (memory only).",
                  "url": "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/data-tiering.html"
                }
              },
              {
                  "id": "waf_ec_cost_dp13_bp5",
                  "title": "None of these",
                  "improvementPlan": {
                    "displayText": "Apply the recommended best practices"
                  },
                  "helpfulResource": {
                    "displayText": "Choose this if your workload does not follow these best practices."
                  }
                }   
            ],
            "riskRules": [
              {
                  "condition": "!waf_ec_cost_dp13_bp1 || !waf_ec_cost_dp13_bp2 || !waf_ec_cost_dp13_bp4 || waf_ec_cost_dp13_bp5",
                  "risk": "HIGH_RISK"
              },
              {
                "condition": "!waf_ec_cost_dp13_bp3 || !waf_ec_cost_dp13_bp4",
                "risk": "MEDIUM_RISK"
              },
              {
                "condition": "waf_ec_cost_dp13_bp1 && waf_ec_cost_dp13_bp2 && waf_ec_cost_dp13_bp3 && waf_ec_cost_dp13_bp4 && waf_ec_cost_dp13_bp5",
                "risk": "NO_RISK"
              }
            ]
          }
        ]
      }
    ]
  }